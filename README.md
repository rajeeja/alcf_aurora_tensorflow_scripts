# TensorFlow on ALCF Aurora

This directory contains scripts and instructions for running TensorFlow jobs on the ALCF Aurora supercomputer. It provides a streamlined workflow for setting up the environment, launching TensorFlow models, and submitting jobs to the Aurora queue. Note, the focus is to utilize one node and all GPU/tile available. Running multiple models in one node. This is specifically good for running HPOs and other such workflows.

## Purpose

The primary goal of this directory is to provide a simple and reproducible environment for training and evaluating TensorFlow models on the Aurora supercomputer. It includes scripts for managing the environment, submitting jobs, and monitoring progress.

## Files

### Input Files

*   `h.py`: This Python script contains the TensorFlow model definition, training logic, and evaluation metrics. Users will need to modify this file to implement their specific model and training procedure.
*   `run_h.sh`: This Bash script sets up the necessary environment variables, configures the TensorFlow runtime, and launches the `h.py` script. It is responsible for preparing the execution environment for the TensorFlow job.
*   `submit.sh`: This Bash script submits the job to the Aurora queue using the `qsub` command. It specifies the resources required for the job, such as the number of nodes, the wall time, and the queue to use.

### Output Files

All other files in this directory are output files generated by the `qsub submit.sh` command. These files contain the output and error messages from the submitted jobs and should not be modified directly.

*   `*.output`: These files contain the standard output from the TensorFlow job. They typically include information about the training progress, evaluation metrics, and any other messages printed by the `h.py` script.
*   `*.error`: These files contain the standard error from the TensorFlow job. They may include error messages, warnings, and debugging information.

## Usage

1.  **Modify `h.py`:** Implement your TensorFlow model and training logic in the `h.py` script.
2.  **Configure `run_h.sh`:** Adjust the environment variables and TensorFlow runtime settings in the `run_h.sh` script as needed.
3.  **Submit the job:** Use the `qsub submit.sh` command to submit the job to the Aurora queue.
4.  **Monitor progress:** Monitor the output and error files to track the progress of the job and identify any issues.

## Customization

*   **Model:** To use a different TensorFlow model, modify the `h.py` script to define your model architecture and training procedure.
*   **Dataset:** To train on a different dataset, modify the `h.py` script to load and preprocess your data.
*   **Resources:** To request different resources for your job, modify the `submit.sh` script to specify the desired number of nodes, wall time, and queue.

## Troubleshooting

*   **Job fails to start:** Check the error files for any error messages or warnings. Ensure that all necessary environment variables are set correctly and that the TensorFlow runtime is properly configured.
*   **Job runs slowly:** Check the output files to see if the training progress is as expected. Ensure that the model is not too complex for the available resources and that the data is being loaded and processed efficiently.
*   **Job produces incorrect results:** Check the output files to see if the evaluation metrics are as expected. Ensure that the model is properly trained and that the data is being preprocessed correctly.